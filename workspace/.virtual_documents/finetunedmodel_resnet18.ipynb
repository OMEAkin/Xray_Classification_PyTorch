





# Import required libraries
# -------------------------
# Data loading and plotting
import random
import numpy as np
import matplotlib.pyplot as plt
from torchvision.transforms import transforms
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader

# Train model
import torch
from torchvision import models
import torch.nn as nn
import torch.optim as optim

# Evaluate model
from torchmetrics import Accuracy, F1Score

# Set random seeds for reproducibility
torch.manual_seed(101010)
np.random.seed(101010)
random.seed(101010)











import os
import zipfile

# Unzip the data folder
if not os.path.exists('data/chestxrays'):
    with zipfile.ZipFile('data/chestxrays.zip', 'r') as zip_ref:
        zip_ref.extractall('data')





# check folders within base folder
print(os.listdir('data'))
print(os.listdir('data/chestxrays'))

# define directories
trainimages_dir = os.path.join('data/chestxrays/train')
trainimages_pneu_dir = os.path.join('data/chestxrays/train/PNEUMONIA')
trainimages_norm_dir = os.path.join('data/chestxrays/train/NORMAL')

# check filenames in training directories
trainimages_pneu = os.listdir('data/chestxrays/train/PNEUMONIA')
trainimages_norm = os.listdir('data/chestxrays/train/NORMAL') 
print(f"\nFilenames for Training Pneumonia Images: {trainimages_pneu[:10]}")
print(f"\nFilenames for Training Normal Images: {trainimages_norm[:10]}")





# Data Visualization Packages
import matplotlib as mpimg
from PIL import Image





# matplotlib parameters
nrows = 4
ncols = 4

# index to iterate over images
pic_index = 0

# matplotlib 4 x 4 fig set-up
fig = plt.gcf() # get current image
fig.set_size_inches(24, 24)

pic_index += 8
nxt_pneu_pic = [os.path.join(trainimages_pneu_dir, fname)
                for fname in trainimages_pneu[pic_index-8:pic_index]]
nxt_norm_pic = [os.path.join(trainimages_norm_dir, fname)
                for fname in trainimages_norm[pic_index-8:pic_index]]

for i, img_path in enumerate(nxt_pneu_pic+nxt_norm_pic):
  #create subplot; subplot indices start at 1
  sp = plt.subplot(nrows, ncols, i + 1)
  sp.axis('Off')

  imgs = Image.open(img_path)
  plt.imshow(imgs)





# Define the transformations to apply to the images for use with ResNet-18
transform_mean = [0.485, 0.456, 0.406]
transform_std =[0.229, 0.224, 0.225]
transform = transforms.Compose([transforms.ToTensor(), 
                                transforms.Normalize(mean=transform_mean, std=transform_std)])

# Apply the image transforms
train_df = ImageFolder('data/chestxrays/train', transform=transform)
test_df = ImageFolder('data/chestxrays/test', transform=transform)

# Create data loaders
train_loader = DataLoader(train_df, batch_size=len(train_df) // 2, shuffle=True)
test_loader = DataLoader(test_df, batch_size=len(test_df))





# Check image details
image, label = train_df[0]
print(f"Image size: {image.size()}, Label: {label}]")

for images, labels in train_loader:
    print(images.size(), labels.size())








# load pretrained model: resnet18 
resnet18 = models.resnet18(weights="IMAGENET1K_V1")
for param in resnet18.parameters():
    param.required_grad = False
        
# modify just the last layer
resnet18.fc = nn.Linear(resnet18.fc.in_features, 1)





# run model on GPU if available
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
resnet18.to(device)  # Sending model to device





# specify loss function and optimizer
criterion = nn.BCEWithLogitsLoss()
optimizer = torch.optim.SGD(
    resnet18.fc.parameters(), # only last layer is optimized
    lr=0.0005, # lr should be kept low so that the pre-trained weights don't change easily
    momentum = 0.9
)  





num_epochs = 3

for epoch in range(num_epochs):
    resnet18.train()
    training_loss = 0.0
    
    for images, labels in train_loader:
        images, labels = images.to(device).float(), labels.to(device).float()
        
        # reset gradients
        optimizer.zero_grad()
        
        # forward pass
        outputs = resnet18(images)
        
        # compute loss + backpropagation
        loss = criterion(outputs.squeeze(), labels) # compare output to ground truth
        loss.backward()
        
        # update weights (& bias?)
        optimizer.step()
        
        training_loss += loss.item()
        





# Set model to evaluation mode
model = resnet18
model.eval()

# Initialize metrics for accuracy and F1 score
accuracy_metric = Accuracy(task="binary")
f1_metric = F1Score(task="binary")

# Create lists store all predictions and labels
all_preds = []
all_labels = []

# Disable gradient calculation for evaluation
with torch.no_grad():
  for inputs, labels in test_loader:
    # Forward pass
    outputs = model(inputs)
    preds = torch.sigmoid(outputs).round()  # Round to 0 or 1

    # Extend the lists with predictions and labels
    all_preds.extend(preds.tolist())
    all_labels.extend(labels.unsqueeze(1).tolist())

    # Convert lists back to tensors
    all_preds = torch.tensor(all_preds)
    all_labels = torch.tensor(all_labels)

    # Calculate accuracy and F1 score
    test_acc = accuracy_metric(all_preds, all_labels).item()
    test_f1 = f1_metric(all_preds, all_labels).item()
